#!/usr/bin/env python3
"""
å°çº¢ä¹¦ç¬”è®°è¶‹åŠ¿åˆ†æè„šæœ¬
ç»Ÿè®¡å„ä¸»é¢˜çš„çƒ­åº¦å¹¶è¯†åˆ«æœ€çƒ­é—¨çš„ä¸»é¢˜
"""

import json
import glob
import os
from datetime import datetime
from typing import List, Dict, Tuple
from collections import defaultdict


class TrendAnalyzer:
    """è¶‹åŠ¿åˆ†æå™¨"""
    
    # äº’åŠ¨æƒé‡é…ç½®
    ENGAGEMENT_WEIGHTS = {
        'likes': 1.0,      # ç‚¹èµï¼šåŸºç¡€äº’åŠ¨
        'comments': 2.0,   # è¯„è®ºï¼šæ·±åº¦å‚ä¸
        'collects': 1.5,   # æ”¶è—ï¼šä»·å€¼è®¤å¯
        'shares': 3.0      # åˆ†äº«ï¼šä¼ æ’­ä»·å€¼æœ€é«˜
    }
    
    def __init__(self, data_file: str = None):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            data_file: æ•°æ®æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°æ–‡ä»¶
        """
        if data_file is None:
            data_file = self._find_latest_data_file()
        
        self.data_file = data_file
        self.data = self._load_data()
        print(f"ğŸ“‚ åŠ è½½æ•°æ®æ–‡ä»¶: {data_file}")
        print(f"ğŸ“Š å…±åŠ è½½ {len(self.data['notes'])} æ¡ç¬”è®°æ•°æ®\n")
    
    def _find_latest_data_file(self) -> str:
        """æŸ¥æ‰¾æœ€æ–°çš„æ•°æ®æ–‡ä»¶"""
        # ä¼˜å…ˆä½¿ç”¨latestç‰ˆæœ¬
        latest_file = "xiaohongshu_notes_latest.json"
        if os.path.exists(latest_file):
            return latest_file
        
        # å¦‚æœlatestä¸å­˜åœ¨ï¼ŒæŸ¥æ‰¾å¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶
        files = glob.glob("xiaohongshu_notes_*.json")
        if not files:
            raise FileNotFoundError("æœªæ‰¾åˆ°ç¬”è®°æ•°æ®æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œæ•°æ®è·å–è„šæœ¬")
        
        # æŒ‰æ–‡ä»¶åæ’åºï¼Œè¿”å›æœ€æ–°çš„
        files.sort(reverse=True)
        return files[0]
    
    def _load_data(self) -> Dict:
        """åŠ è½½æ•°æ®æ–‡ä»¶"""
        with open(self.data_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def analyze_trends(self, top_n: int = 5) -> Dict:
        """
        åˆ†æè¶‹åŠ¿å¹¶æå–çƒ­é—¨ä¸»é¢˜
        
        Args:
            top_n: æå–å‰Nä¸ªçƒ­é—¨ä¸»é¢˜
        
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        print("ğŸ” å¼€å§‹åˆ†æè¶‹åŠ¿...")
        
        # æŒ‰ä¸»é¢˜åˆ†ç»„ç»Ÿè®¡
        topic_stats = self._calculate_topic_stats()
        
        # è®¡ç®—çƒ­åº¦è¯„åˆ†
        topic_scores = self._calculate_heat_scores(topic_stats)
        
        # æ’åºå¹¶æå–Top N
        sorted_topics = sorted(
            topic_scores.items(),
            key=lambda x: x[1]['heat_score'],
            reverse=True
        )[:top_n]
        
        # æ„å»ºåˆ†æç»“æœ
        result = {
            "analysis_time": datetime.now().isoformat(),
            "data_source": self.data_file,
            "total_notes": len(self.data['notes']),
            "total_topics": len(topic_stats),
            "top_n": top_n,
            "top_topics": []
        }
        
        print(f"\nğŸŒŸ è¯†åˆ«å‡º Top {top_n} çƒ­é—¨ä¸»é¢˜ï¼š\n")
        
        for rank, (topic, stats) in enumerate(sorted_topics, 1):
            topic_result = {
                "rank": rank,
                "topic": topic,
                "note_count": stats['note_count'],
                "total_engagement": stats['total_engagement'],
                "heat_score": round(stats['heat_score'], 2),
                "avg_engagement_per_note": round(stats['avg_engagement'], 2),
                "sample_notes": stats['sample_notes'][:3]  # å–3ä¸ªæ ·æœ¬ç¬”è®°ID
            }
            result['top_topics'].append(topic_result)
            
            # æ‰“å°ç»“æœ
            print(f"  {rank}. {topic}")
            print(f"     ğŸ“ ç¬”è®°æ•°: {stats['note_count']}")
            print(f"     ğŸ”¥ çƒ­åº¦è¯„åˆ†: {stats['heat_score']:.2f}")
            print(f"     ğŸ’¬ æ€»äº’åŠ¨é‡: {stats['weighted_engagement']:.0f}")
            print(f"     ğŸ“ˆ å¹³å‡äº’åŠ¨: {stats['avg_engagement']:.2f}/ç¯‡")
            print()
        
        return result
    
    def _calculate_topic_stats(self) -> Dict[str, Dict]:
        """è®¡ç®—æ¯ä¸ªä¸»é¢˜çš„ç»Ÿè®¡æ•°æ®"""
        topic_data = defaultdict(lambda: {
            'notes': [],
            'total_likes': 0,
            'total_comments': 0,
            'total_collects': 0,
            'total_shares': 0,
        })
        
        for note in self.data['notes']:
            topic = note['topic']
            stats = note['stats']
            
            topic_data[topic]['notes'].append(note)
            topic_data[topic]['total_likes'] += stats['likes']
            topic_data[topic]['total_comments'] += stats['comments']
            topic_data[topic]['total_collects'] += stats['collects']
            topic_data[topic]['total_shares'] += stats['shares']
        
        return topic_data
    
    def _calculate_heat_scores(self, topic_stats: Dict) -> Dict[str, Dict]:
        """
        è®¡ç®—çƒ­åº¦è¯„åˆ†
        
        å…¬å¼ï¼šçƒ­åº¦åˆ†æ•° = ä¸»é¢˜ç¬”è®°æ•° Ã— 10 + åŠ æƒäº’åŠ¨é‡ / 100
        """
        results = {}
        
        for topic, data in topic_stats.items():
            note_count = len(data['notes'])
            
            # è®¡ç®—åŠ æƒäº’åŠ¨é‡
            weighted_engagement = (
                data['total_likes'] * self.ENGAGEMENT_WEIGHTS['likes'] +
                data['total_comments'] * self.ENGAGEMENT_WEIGHTS['comments'] +
                data['total_collects'] * self.ENGAGEMENT_WEIGHTS['collects'] +
                data['total_shares'] * self.ENGAGEMENT_WEIGHTS['shares']
            )
            
            # è®¡ç®—çƒ­åº¦è¯„åˆ†
            heat_score = note_count * 10 + weighted_engagement / 100
            
            # è®¡ç®—å¹³å‡äº’åŠ¨é‡
            total_engagement = (
                data['total_likes'] +
                data['total_comments'] +
                data['total_collects'] +
                data['total_shares']
            )
            avg_engagement = total_engagement / note_count if note_count > 0 else 0
            
            results[topic] = {
                'note_count': note_count,
                'total_engagement': {
                    'likes': data['total_likes'],
                    'comments': data['total_comments'],
                    'collects': data['total_collects'],
                    'shares': data['total_shares']
                },
                'weighted_engagement': weighted_engagement,
                'heat_score': heat_score,
                'avg_engagement': avg_engagement,
                'sample_notes': [note['note_id'] for note in data['notes']]
            }
        
        return results
    
    def save_analysis(self, result: Dict, filename: str = None) -> str:
        """ä¿å­˜åˆ†æç»“æœï¼ˆåŒæ—¶ä¿å­˜å¸¦æ—¶é—´æˆ³å’Œlatestç‰ˆæœ¬ï¼‰"""
        if filename is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"trend_analysis_{timestamp}.json"
        
        # ä¿å­˜å¸¦æ—¶é—´æˆ³çš„ç‰ˆæœ¬ï¼ˆå†å²è®°å½•ï¼‰
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ åˆ†æç»“æœå·²ä¿å­˜åˆ°: {filename}")
        
        # ä¿å­˜latestç‰ˆæœ¬ï¼ˆä¾›ç½‘é¡µè¯»å–ï¼‰
        latest_filename = "trend_analysis_latest.json"
        with open(latest_filename, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ æœ€æ–°åˆ†æå·²æ›´æ–°: {latest_filename}")
        
        return filename
    
    def generate_report(self, result: Dict):
        """ç”Ÿæˆå¯è¯»çš„åˆ†ææŠ¥å‘Š"""
        print("\n" + "="*60)
        print("ğŸ“Š è¶‹åŠ¿åˆ†ææŠ¥å‘Š")
        print("="*60)
        print(f"åˆ†ææ—¶é—´: {result['analysis_time']}")
        print(f"æ•°æ®æ¥æº: {result['data_source']}")
        print(f"æ€»ç¬”è®°æ•°: {result['total_notes']}")
        print(f"ä¸»é¢˜æ€»æ•°: {result['total_topics']}")
        print(f"\nğŸ† Top {result['top_n']} çƒ­é—¨ä¸»é¢˜è¯¦æƒ…:\n")
        
        for topic in result['top_topics']:
            print(f"æ’å #{topic['rank']}: {topic['topic']}")
            print(f"  â€¢ ç¬”è®°æ•°é‡: {topic['note_count']} ç¯‡")
            print(f"  â€¢ çƒ­åº¦è¯„åˆ†: {topic['heat_score']}")
            print(f"  â€¢ å¹³å‡äº’åŠ¨: {topic['avg_engagement_per_note']:.2f} æ¬¡/ç¯‡")
            print()
        
        print("="*60)
        print("ğŸ’¡ å†…å®¹åˆ›ä½œå»ºè®®:")
        print("="*60)
        print("åŸºäºä»¥ä¸Šçƒ­é—¨ä¸»é¢˜ï¼Œå»ºè®®é‡ç‚¹åˆ›ä½œä»¥ä¸‹æ–¹å‘çš„å†…å®¹ï¼š")
        for i, topic in enumerate(result['top_topics'][:3], 1):
            print(f"{i}. {topic['topic']} - çƒ­åº¦è¯„åˆ† {topic['heat_score']}")
        print()


def main():
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºåˆ†æå™¨
    analyzer = TrendAnalyzer()
    
    # æ‰§è¡Œåˆ†æ
    result = analyzer.analyze_trends(top_n=5)
    
    # ä¿å­˜ç»“æœ
    filename = analyzer.save_analysis(result)
    
    # ç”ŸæˆæŠ¥å‘Š
    analyzer.generate_report(result)
    
    print("âœ… ç¬¬äºŒæ­¥å®Œæˆï¼å·²è¯†åˆ«çƒ­é—¨ä¸»é¢˜ï¼Œå‡†å¤‡ç”Ÿæˆå†…å®¹ã€‚\n")
    
    return filename


if __name__ == "__main__":
    main()
